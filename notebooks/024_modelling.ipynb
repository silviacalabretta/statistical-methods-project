{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c59f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19367ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aae413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split complete. Training: 10728 rows, Test: 2683 rows.\n",
      "Split complete. Training: 68735 rows, Test: 17184 rows.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10728 entries, 0 to 79909\n",
      "Data columns (total 13 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   Domestic                           10728 non-null  int64  \n",
      " 1   TripReason                         10728 non-null  int64  \n",
      " 2   LeadTime_Days                      10728 non-null  float64\n",
      " 3   LogPrice                           10728 non-null  float64\n",
      " 4   TimeOfDay_Afternoon                10728 non-null  int64  \n",
      " 5   TimeOfDay_Evening                  10728 non-null  int64  \n",
      " 6   TimeOfDay_Morning                  10728 non-null  int64  \n",
      " 7   TimeOfDay_Night                    10728 non-null  int64  \n",
      " 8   From_Rate                          10728 non-null  float64\n",
      " 9   To_Rate                            10728 non-null  float64\n",
      " 10  Route_Rate                         10728 non-null  float64\n",
      " 11  User_Rate                          10728 non-null  float64\n",
      " 12  cancel_rate_per_vehicle_and_price  10728 non-null  float64\n",
      "dtypes: float64(7), int64(6)\n",
      "memory usage: 1.1 MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domestic</th>\n",
       "      <th>TripReason</th>\n",
       "      <th>LeadTime_Days</th>\n",
       "      <th>LogPrice</th>\n",
       "      <th>TimeOfDay_Afternoon</th>\n",
       "      <th>TimeOfDay_Evening</th>\n",
       "      <th>TimeOfDay_Morning</th>\n",
       "      <th>TimeOfDay_Night</th>\n",
       "      <th>From_Rate</th>\n",
       "      <th>To_Rate</th>\n",
       "      <th>Route_Rate</th>\n",
       "      <th>User_Rate</th>\n",
       "      <th>cancel_rate_per_vehicle_and_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.597348</td>\n",
       "      <td>15.702580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145227</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.156824</td>\n",
       "      <td>0.114425</td>\n",
       "      <td>0.113812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.557834</td>\n",
       "      <td>16.066802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.163560</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.182062</td>\n",
       "      <td>0.137310</td>\n",
       "      <td>0.113812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.740009</td>\n",
       "      <td>16.044341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142249</td>\n",
       "      <td>0.104860</td>\n",
       "      <td>0.113083</td>\n",
       "      <td>0.292909</td>\n",
       "      <td>0.113812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.482153</td>\n",
       "      <td>15.616065</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.129168</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.148526</td>\n",
       "      <td>0.114425</td>\n",
       "      <td>0.113812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.821631</td>\n",
       "      <td>16.593522</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142249</td>\n",
       "      <td>0.082844</td>\n",
       "      <td>0.086369</td>\n",
       "      <td>0.114425</td>\n",
       "      <td>0.113812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Domestic  TripReason  LeadTime_Days   LogPrice  TimeOfDay_Afternoon  \\\n",
       "0          1           1      10.597348  15.702580                    0   \n",
       "1          1           0       2.557834  16.066802                    0   \n",
       "6          1           1       7.740009  16.044341                    0   \n",
       "11         1           1       0.482153  15.616065                    0   \n",
       "15         0           1       0.821631  16.593522                    0   \n",
       "\n",
       "    TimeOfDay_Evening  TimeOfDay_Morning  TimeOfDay_Night  From_Rate  \\\n",
       "0                   0                  0                1   0.145227   \n",
       "1                   0                  0                1   0.163560   \n",
       "6                   0                  1                0   0.142249   \n",
       "11                  0                  0                1   0.129168   \n",
       "15                  0                  1                0   0.142249   \n",
       "\n",
       "     To_Rate  Route_Rate  User_Rate  cancel_rate_per_vehicle_and_price  \n",
       "0   0.148492    0.156824   0.114425                           0.113812  \n",
       "1   0.148492    0.182062   0.137310                           0.113812  \n",
       "6   0.104860    0.113083   0.292909                           0.113812  \n",
       "11  0.148492    0.148526   0.114425                           0.113812  \n",
       "15  0.082844    0.086369   0.114425                           0.113812  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    " # Split the data\n",
    "def split(data, id_col=\"Index\", target_col='Cancel', train_size=0.8):\n",
    "    split_index = int(len(data) * train_size)\n",
    "    train_df = data.iloc[:split_index].copy()\n",
    "    test_df  = data.iloc[split_index:].copy()\n",
    "        \n",
    "    print(f\"Split complete. Training: {len(train_df)} rows, Test: {len(test_df)} rows.\")\n",
    "\n",
    "    # Final Clean-up: drop the ID and the Date column\n",
    "    train_df = train_df.drop(columns=[id_col])\n",
    "    test_df = test_df.drop(columns=[id_col])\n",
    "\n",
    "    X_train = train_df.drop(columns=['Cancel'])\n",
    "    y_train = train_df['Cancel']\n",
    "\n",
    "    X_test = test_df.drop(columns=['Cancel'])\n",
    "    y_test = test_df['Cancel']\n",
    "\n",
    "    # Convert it to a Series for Statsmodels.\n",
    "    y_train = y_train.squeeze()\n",
    "    y_test = y_test.squeeze()\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "df=pd.read_csv(\"../data/updated_data2.csv\")\n",
    "\n",
    "df_plane = df[df['Vehicle_Plane'] == 1].copy()\n",
    "\n",
    "# Rimuoviamo le colonne dei veicoli che ora sono ridondanti (tutti sono Plane)\n",
    "df_plane = df_plane.drop(columns=['Vehicle_Plane', 'Vehicle_Bus', 'Vehicle_Train'])\n",
    "\n",
    "# 2. Creazione del DataFrame per TERRESTRI (Treni e Bus)\n",
    "# Filtriamo dove Vehicle_Train o Vehicle_Bus sono 1\n",
    "df_terrestrial = df[(df['Vehicle_Train'] == 1) | (df['Vehicle_Bus'] == 1)].copy()\n",
    "df_terrestrial = df_terrestrial.drop(columns=['Vehicle_Plane', 'Vehicle_Bus', 'Vehicle_Train'])\n",
    "\n",
    "X_train_plane, y_train_plane, X_test_plane, y_test_plane=split(df_plane)\n",
    "X_train_train, y_train_train, X_test_train, y_test_train=split(df_terrestrial)\n",
    "\n",
    "print(X_train_plane.info())\n",
    "X_train_plane.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b67454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference categories dropped. Ready for VIF check or Modeling.\n",
      "Reference categories dropped. Ready for VIF check or Modeling.\n",
      "               feature       VIF\n",
      "5           Route_Rate  7.284695\n",
      "6            User_Rate  6.901697\n",
      "2  TimeOfDay_Afternoon  2.569271\n",
      "4    TimeOfDay_Morning  2.545879\n",
      "3    TimeOfDay_Evening  2.457656\n",
      "0           TripReason  1.937560\n",
      "1        LeadTime_Days  1.851600\n",
      "               feature       VIF\n",
      "5           Route_Rate  7.055179\n",
      "6            User_Rate  5.615913\n",
      "2  TimeOfDay_Afternoon  2.431548\n",
      "0           TripReason  2.360429\n",
      "3    TimeOfDay_Evening  2.204024\n",
      "1        LeadTime_Days  1.753330\n",
      "4    TimeOfDay_Morning  1.708805\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of reference categories to drop\n",
    "# (We drop 'Bus' and 'Night' so they become the standard baseline)\n",
    "def drops(X_train, X_test):                                                         #O sostituisci con solo \"cancel_rate_per_vehicle_and_price\"\n",
    "    cols_to_drop = ['TimeOfDay_Night','From_Rate', 'To_Rate', 'Domestic','LogPrice',\"cancel_rate_per_vehicle_and_price\"]\n",
    "\n",
    "    # Apply the drops\n",
    "    X_train = X_train.drop(columns=cols_to_drop)\n",
    "    X_test = X_test.drop(columns=cols_to_drop)\n",
    "\n",
    "    print(\"Reference categories dropped. Ready for VIF check or Modeling.\")\n",
    "    return X_train,X_test\n",
    "\n",
    "# Create a VIF dataframe\n",
    "def vif(X_train):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X_train.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X_train.values, i) \n",
    "                    for i in range(len(X_train.columns))]\n",
    "\n",
    "    print(vif_data.sort_values(by=\"VIF\", ascending=False))\n",
    "\n",
    "\n",
    "X_train_plane, X_test_plane=drops(X_train_plane, X_test_plane)\n",
    "X_train_train, X_test_train=drops(X_train_train, X_test_train)\n",
    "\n",
    "vif(X_train_plane)\n",
    "vif(X_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f89c6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: APPLY SMOTE TO TRAINING DATA ONLY\n",
      "======================================================================\n",
      "\n",
      "BEFORE Oversampling (Training Data):\n",
      "Class 0 (No Cancel): 9517 samples\n",
      "Class 1 (Cancel):    1211 samples\n",
      "Ratio: 11.29% cancellations\n",
      "\n",
      "AFTER Oversampling (Training Data):\n",
      "Class 0 (No Cancel): 9517 samples\n",
      "Class 1 (Cancel):    9517 samples\n",
      "Ratio: 50.00% cancellations\n",
      "======================================================================\n",
      "STEP 1: APPLY SMOTE TO TRAINING DATA ONLY\n",
      "======================================================================\n",
      "\n",
      "BEFORE Oversampling (Training Data):\n",
      "Class 0 (No Cancel): 59087 samples\n",
      "Class 1 (Cancel):    9648 samples\n",
      "Ratio: 14.04% cancellations\n",
      "\n",
      "AFTER Oversampling (Training Data):\n",
      "Class 0 (No Cancel): 59087 samples\n",
      "Class 1 (Cancel):    59087 samples\n",
      "Ratio: 50.00% cancellations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "def oversample(X_train,y_train):\n",
    "    print(\"=\"*70)\n",
    "    print(\"STEP 1: APPLY SMOTE TO TRAINING DATA ONLY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(\"\\nBEFORE Oversampling (Training Data):\")\n",
    "    print(f\"Class 0 (No Cancel): {(y_train == 0).sum()} samples\")\n",
    "    print(f\"Class 1 (Cancel):    {(y_train == 1).sum()} samples\")\n",
    "    print(f\"Ratio: {((y_train == 1).sum() / len(y_train)) * 100:.2f}% cancellations\")\n",
    "\n",
    "    # Apply SMOTE ONLY to training data\n",
    "    # SMOTE creates synthetic samples of the minority class (1) to match majority class (0)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\nAFTER Oversampling (Training Data):\")\n",
    "    print(f\"Class 0 (No Cancel): {(y_train_balanced == 0).sum()} samples\")\n",
    "    print(f\"Class 1 (Cancel):    {(y_train_balanced == 1).sum()} samples\")\n",
    "    print(f\"Ratio: {((y_train_balanced == 1).sum() / len(y_train_balanced)) * 100:.2f}% cancellations\")\n",
    "    return X_train_balanced, y_train_balanced\n",
    "\n",
    "X_train_plane_balanced, y_train_plane_balanced=oversample(X_train_plane, y_train_plane)\n",
    "X_train_train_balanced, y_train_train_balanced=oversample(X_train_train, y_train_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af4b2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: APPLY STANDARD SCALING\n",
      "======================================================================\n",
      "Scaling applied successfully!\n",
      "X_train_balanced_scaled shape: (19034, 7)\n",
      "X_test_scaled shape: (2683, 7)\n",
      "Scaling applied successfully!\n",
      "X_train_balanced_scaled shape: (118174, 7)\n",
      "X_test_scaled shape: (17184, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: APPLY STANDARD SCALING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Fit scaler on balanced training data, transform both train and test\n",
    "def scale(X_train_balanced,X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_balanced_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train_balanced), \n",
    "        columns=X_train_balanced.columns\n",
    "    )\n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test), \n",
    "        columns=X_test.columns\n",
    "    )\n",
    "\n",
    "    print(\"Scaling applied successfully!\")\n",
    "    print(f\"X_train_balanced_scaled shape: {X_train_balanced_scaled.shape}\")\n",
    "    print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "    return X_train_balanced_scaled,X_test_scaled\n",
    "X_train_plane_balanced_scaled,X_test_plane_scaled = scale(X_train_plane_balanced,X_test_plane)\n",
    "X_train_train_balanced_scaled,X_test_train_scaled = scale(X_train_train_balanced,X_test_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726375e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 3: BASELINE MODEL - cancel_rate_per_vehicle_and_price Only\n",
      "======================================================================\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 Cancel   No. Observations:                19034\n",
      "Model:                            GLM   Df Residuals:                    19032\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -12833.\n",
      "Date:                Tue, 27 Jan 2026   Deviance:                       25665.\n",
      "Time:                        11:59:59   Pearson chi2:                 1.92e+04\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):            0.03720\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0113      0.015      0.762      0.446      -0.018       0.040\n",
      "User_Rate      0.4210      0.017     24.995      0.000       0.388       0.454\n",
      "==============================================================================\n",
      "\n",
      "AIC: 25669.16\n",
      "Log-Likelihood: -12832.58\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 Cancel   No. Observations:               118174\n",
      "Model:                            GLM   Df Residuals:                   118172\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -79133.\n",
      "Date:                Tue, 27 Jan 2026   Deviance:                   1.5827e+05\n",
      "Time:                        12:00:00   Pearson chi2:                 1.19e+05\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):            0.04595\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.0144      0.006      2.400      0.016       0.003       0.026\n",
      "User_Rate      0.4738      0.007     68.850      0.000       0.460       0.487\n",
      "==============================================================================\n",
      "\n",
      "AIC: 158269.32\n",
      "Log-Likelihood: -79132.66\n"
     ]
    }
   ],
   "source": [
    "# === STEP 3: BASELINE MODEL (LogLeadTime Only) ===\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 3: BASELINE MODEL - cancel_rate_per_vehicle_and_price Only\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def baseline_mode_create(X_train_balanced_scaled,X_test_scaled,y_train_balanced,feature=\"cancel_rate_per_vehicle_and_price\"):\n",
    "    # Prepare baseline data (LogLeadTime only) from scaled data\n",
    "    X_train_balanced_scaled_baseline = X_train_balanced_scaled[[feature]].copy()\n",
    "    X_train_balanced_scaled_baseline_const = sm.add_constant(X_train_balanced_scaled_baseline)\n",
    "\n",
    "    X_test_scaled_baseline = X_test_scaled[[feature]].copy()\n",
    "    X_test_scaled_baseline_const = sm.add_constant(X_test_scaled_baseline)\n",
    "\n",
    "    # Fit baseline model\n",
    "    baseline_model = sm.GLM(y_train_balanced, X_train_balanced_scaled_baseline_const, \n",
    "                            family=sm.families.Binomial()).fit()\n",
    "\n",
    "    print(baseline_model.summary())\n",
    "\n",
    "    # Predictions using threshold = 0.5\n",
    "    threshold = 0.5\n",
    "    y_pred_prob_baseline = baseline_model.predict(X_test_scaled_baseline_const)\n",
    "    y_pred_baseline = (y_pred_prob_baseline >= threshold).astype(int)\n",
    "\n",
    "    print(f\"\\nAIC: {baseline_model.aic:.2f}\")\n",
    "    print(f\"Log-Likelihood: {baseline_model.llf:.2f}\")\n",
    "\n",
    "    return baseline_model, y_pred_prob_baseline, y_pred_baseline\n",
    "\n",
    "baseline_model_plane, y_pred_prob_baseline_plane, y_pred_baseline_plane = baseline_mode_create(X_train_plane_balanced_scaled,X_test_plane_scaled,y_train_plane_balanced, feature=\"User_Rate\")\n",
    "baseline_model_train, y_pred_prob_baseline_train, y_pred_baseline_train = baseline_mode_create(X_train_train_balanced_scaled,X_test_train_scaled,y_train_train_balanced, feature=\"User_Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057af2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 4: FULL MODEL - ALL FEATURES\n",
      "======================================================================\n",
      "Features nel modello (training): ['const', 'TripReason', 'LeadTime_Days', 'TimeOfDay_Afternoon', 'TimeOfDay_Evening', 'TimeOfDay_Morning', 'Route_Rate', 'User_Rate']\n",
      "Features nel dataset di test: ['const', 'TripReason', 'LeadTime_Days', 'TimeOfDay_Afternoon', 'TimeOfDay_Evening', 'TimeOfDay_Morning', 'Route_Rate', 'User_Rate']\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 Cancel   No. Observations:                19034\n",
      "Model:                            GLM   Df Residuals:                    19026\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -12471.\n",
      "Date:                Tue, 27 Jan 2026   Deviance:                       24941.\n",
      "Time:                        12:00:06   Pearson chi2:                 5.33e+04\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):            0.07313\n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.0178      0.015      1.178      0.239      -0.012       0.047\n",
      "TripReason              0.1915      0.016     11.842      0.000       0.160       0.223\n",
      "LeadTime_Days           0.3907      0.018     21.668      0.000       0.355       0.426\n",
      "TimeOfDay_Afternoon     0.0723      0.023      3.124      0.002       0.027       0.118\n",
      "TimeOfDay_Evening       0.0939      0.023      4.151      0.000       0.050       0.138\n",
      "TimeOfDay_Morning       0.0121      0.023      0.526      0.599      -0.033       0.057\n",
      "Route_Rate              0.1926      0.015     12.484      0.000       0.162       0.223\n",
      "User_Rate               0.4039      0.017     23.393      0.000       0.370       0.438\n",
      "=======================================================================================\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON: BASELINE vs FULL MODEL\n",
      "======================================================================\n",
      "            Metric Baseline (LogLeadTime) Full Model (All)\n",
      "               AIC               25669.16         24957.26\n",
      "               BIC             -161875.83       -162540.61\n",
      "    Log-Likelihood              -12832.58        -12470.63\n",
      "Cross-Entropy Loss                 0.6693           0.6602\n",
      "     Features Used                      1                7\n",
      "Metric          Baseline        Full Model     \n",
      "---------------------------------------------\n",
      "Accuracy        0.8412          0.6802         \n",
      "Precision       0.2909          0.1937         \n",
      "Recall          0.2572          0.5563         \n",
      "F1-Score        0.2730          0.2874         \n",
      "ROC-AUC         0.5851          0.6688         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessiovalle/GitRepos/statistical-methods-project/venv/lib/python3.12/site-packages/statsmodels/genmod/generalized_linear_model.py:1923: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features nel modello (training): ['const', 'TripReason', 'LeadTime_Days', 'TimeOfDay_Afternoon', 'TimeOfDay_Evening', 'TimeOfDay_Morning', 'Route_Rate', 'User_Rate']\n",
      "Features nel dataset di test: ['const', 'TripReason', 'LeadTime_Days', 'TimeOfDay_Afternoon', 'TimeOfDay_Evening', 'TimeOfDay_Morning', 'Route_Rate', 'User_Rate']\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                 Cancel   No. Observations:               118174\n",
      "Model:                            GLM   Df Residuals:                   118166\n",
      "Model Family:                Binomial   Df Model:                            7\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -76686.\n",
      "Date:                Tue, 27 Jan 2026   Deviance:                   1.5337e+05\n",
      "Time:                        12:00:06   Pearson chi2:                 1.19e+05\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):            0.08465\n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   0.0136      0.006      2.221      0.026       0.002       0.026\n",
      "TripReason              0.0686      0.007     10.455      0.000       0.056       0.082\n",
      "LeadTime_Days           0.2180      0.007     31.097      0.000       0.204       0.232\n",
      "TimeOfDay_Afternoon    -0.0322      0.008     -3.815      0.000      -0.049      -0.016\n",
      "TimeOfDay_Evening      -0.0751      0.008     -9.113      0.000      -0.091      -0.059\n",
      "TimeOfDay_Morning      -0.0288      0.008     -3.694      0.000      -0.044      -0.014\n",
      "Route_Rate              0.3524      0.007     52.558      0.000       0.339       0.366\n",
      "User_Rate               0.4126      0.007     59.315      0.000       0.399       0.426\n",
      "=======================================================================================\n",
      "\n",
      "======================================================================\n",
      "MODEL COMPARISON: BASELINE vs FULL MODEL\n",
      "======================================================================\n",
      "            Metric Baseline (LogLeadTime) Full Model (All)\n",
      "               AIC              158269.32        153387.91\n",
      "               BIC            -1221973.41      -1226796.73\n",
      "    Log-Likelihood              -79132.66        -76685.96\n",
      "Cross-Entropy Loss                 0.6719           0.6515\n",
      "     Features Used                      1                7\n",
      "Metric          Baseline        Full Model     \n",
      "---------------------------------------------\n",
      "Accuracy        0.7897          0.6510         \n",
      "Precision       0.2896          0.2167         \n",
      "Recall          0.3188          0.5468         \n",
      "F1-Score        0.3035          0.3104         \n",
      "ROC-AUC         0.5963          0.6599         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alessiovalle/GitRepos/statistical-methods-project/venv/lib/python3.12/site-packages/statsmodels/genmod/generalized_linear_model.py:1923: FutureWarning: The bic value is computed using the deviance formula. After 0.13 this will change to the log-likelihood based formula. This change has no impact on the relative rank of models compared using BIC. You can directly access the log-likelihood version using the `bic_llf` attribute. You can suppress this message by calling statsmodels.genmod.generalized_linear_model.SET_USE_BIC_LLF with True to get the LLF-based version now or False to retainthe deviance version.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.genmod.generalized_linear_model.GLMResultsWrapper at 0x798a5c1ca720>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === STEP 4: FULL MODEL WITH ALL FEATURES ===\n",
    "from scipy import stats\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP 4: FULL MODEL - ALL FEATURES\")\n",
    "print(\"=\"*70)\n",
    "def complete_model_create_and_compare(X_train_balanced_scaled,X_test_scaled,y_train_balanced, y_test, y_pred_prob_baseline,baseline_model, y_pred_baseline):\n",
    "    # Add constant to scaled data\n",
    "    X_train_balanced_scaled_const = sm.add_constant(X_train_balanced_scaled)\n",
    "    X_test_scaled_const = sm.add_constant(X_test_scaled, has_constant='add')\n",
    "\n",
    "    # Per evitare altri ValueError, assicurati che l'ordine delle colonne sia IDENTICO al train\n",
    "    X_test_scaled_const = X_test_scaled_const[X_train_balanced_scaled_const.columns]\n",
    "\n",
    "    # Fit full model on balanced and scaled training data\n",
    "    full_model = sm.GLM(y_train_balanced, X_train_balanced_scaled_const, \n",
    "                        family=sm.families.Binomial()).fit()\n",
    "\n",
    "    print(f\"Features nel modello (training): {full_model.params.index.tolist()}\")\n",
    "    print(f\"Features nel dataset di test: {X_test_scaled_const.columns.tolist()}\")\n",
    "    print(full_model.summary())\n",
    "\n",
    "    # Predictions using threshold = 0.5\n",
    "    threshold = 0.5\n",
    "    y_pred_prob_full = full_model.predict(X_test_scaled_const)\n",
    "    y_pred_full = (y_pred_prob_full >= threshold).astype(int)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"MODEL COMPARISON: BASELINE vs FULL MODEL\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Cross-Entropy Loss\n",
    "    baseline_cross_entropy = log_loss(y_test, y_pred_prob_baseline)\n",
    "    full_cross_entropy = log_loss(y_test, y_pred_prob_full)\n",
    "\n",
    "    # Create comparison dataframe\n",
    "    comparison_data = {\n",
    "        'Metric': ['AIC', 'BIC', 'Log-Likelihood', 'Cross-Entropy Loss', 'Features Used'],\n",
    "        'Baseline (LogLeadTime)': [\n",
    "            f\"{baseline_model.aic:.2f}\",\n",
    "            f\"{baseline_model.bic:.2f}\",\n",
    "            f\"{baseline_model.llf:.2f}\",\n",
    "            f\"{baseline_cross_entropy:.4f}\",\n",
    "            \"1\"\n",
    "        ],\n",
    "        'Full Model (All)': [\n",
    "            f\"{full_model.aic:.2f}\",\n",
    "            f\"{full_model.bic:.2f}\",\n",
    "            f\"{full_model.llf:.2f}\",\n",
    "            f\"{full_cross_entropy:.4f}\",\n",
    "            f\"{len(X_train_balanced_scaled.columns)}\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "\n",
    "\n",
    "    # Performance comparison\n",
    "    print(f\"{'Metric':<15} {'Baseline':<15} {'Full Model':<15}\")\n",
    "    print(\"-\"*45)\n",
    "\n",
    "    baseline_acc = accuracy_score(y_test, y_pred_baseline)\n",
    "    full_acc = accuracy_score(y_test, y_pred_full)\n",
    "    print(f\"{'Accuracy':<15} {baseline_acc:<15.4f} {full_acc:<15.4f}\")\n",
    "\n",
    "    baseline_prec = precision_score(y_test, y_pred_baseline, zero_division=0)\n",
    "    full_prec = precision_score(y_test, y_pred_full, zero_division=0)\n",
    "    print(f\"{'Precision':<15} {baseline_prec:<15.4f} {full_prec:<15.4f}\")\n",
    "\n",
    "    baseline_rec = recall_score(y_test, y_pred_baseline, zero_division=0)\n",
    "    full_rec = recall_score(y_test, y_pred_full, zero_division=0)\n",
    "    print(f\"{'Recall':<15} {baseline_rec:<15.4f} {full_rec:<15.4f}\")\n",
    "\n",
    "    baseline_f1 = f1_score(y_test, y_pred_baseline, zero_division=0)\n",
    "    full_f1 = f1_score(y_test, y_pred_full, zero_division=0)\n",
    "    print(f\"{'F1-Score':<15} {baseline_f1:<15.4f} {full_f1:<15.4f}\")\n",
    "\n",
    "    baseline_auc = roc_auc_score(y_test, y_pred_prob_baseline)\n",
    "    full_auc = roc_auc_score(y_test, y_pred_prob_full)\n",
    "    print(f\"{'ROC-AUC':<15} {baseline_auc:<15.4f} {full_auc:<15.4f}\")\n",
    "    return full_model\n",
    "complete_model_create_and_compare(X_train_plane_balanced_scaled,X_test_plane_scaled,y_train_plane_balanced, y_test_plane, y_pred_prob_baseline_plane,baseline_model_plane, y_pred_baseline_plane)\n",
    "complete_model_create_and_compare(X_train_train_balanced_scaled,X_test_train_scaled,y_train_train_balanced, y_test_train, y_pred_prob_baseline_train,baseline_model_train, y_pred_baseline_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
